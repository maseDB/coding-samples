{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Project Purpose: Website scraping using BeautifulSoup\n",
    "\n",
    "## Project Details:\n",
    "\n",
    "Website www.gurufocus.com/stock-market-valuations.php has stocks that are UP the most on the day (gainers) and stocks that are down the most on the day (losers), on its website. This program scarpes the website and appends the scraped information to a file.\n",
    "\n",
    "The Python \"class\" Guru_Scrape which contains the following methods/functions:\n",
    "\n",
    "1) __init__:  Guru_Scrape class requires 3 parameters: URL, main & backup \n",
    "Parameters: \n",
    " URL - URL to be scraped\n",
    " main - file where the scraped info will be appended and saved\n",
    " backup - file where a previous snap shot of the main file will be saved before being modified\n",
    "\n",
    "2) get_soup: Request to get the content of the webpage using Python libraries\n",
    "\n",
    "3) find__gainers_losers: Iterates through 'td' tags to find gainers & losers data\n",
    "\n",
    "4) create_gainers_loser_df: Apply day-and-time stamp and then place found data in dataframe to be appended to the existing file \n",
    "Parameters:\n",
    " win_loss_all - An array of information that has been extracted\n",
    "\n",
    "5) append_file: Append data from dataframe\n",
    "\n",
    "6) backup_file: Backup file before appending new information\n",
    "\n",
    "7) initialize_file: Initialize and prepare the file to be written to\n",
    "\n",
    "8) print_file: print any csv file\n",
    "Parameter(s):\n",
    " File - file to be printed \n",
    "\n",
    "\n",
    "Note: The Guru_Scape class can be easily modified to scrape ANY website.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from pathlib import Path\n",
    "\n",
    "class Guru_Scrape():\n",
    "      soup = \"\"\n",
    "      df_guru = pd.DataFrame()\n",
    "    \n",
    "      def __init__(self, URL, main, backup):\n",
    "          self.URL = URL  \n",
    "          self.main = main\n",
    "          self.backup = backup\n",
    "          self.get_soup()\n",
    "          self.backup_file()\n",
    "          \n",
    "      def get_soup(self):\n",
    "          webpage_response =  requests.get(self.URL)\n",
    "          webpage = webpage_response.content\n",
    "          self.soup= BeautifulSoup(webpage, \"html.parser\")\n",
    "        \n",
    "      def find__gainers_losers(self):\n",
    "          td_tags = self.soup.find_all(['td'])\n",
    "        \n",
    "          win_loss = []\n",
    "          win_loss_all = []\n",
    "          count = 1           \n",
    "          for td_tag in td_tags:  \n",
    "              if len(win_loss_all) < 10:\n",
    "                 win_loss.append(' '.join(td_tag.text.split()))\n",
    "                 count+= 1\n",
    "                 if count == 5:\n",
    "                    win_loss_all.append(win_loss)\n",
    "                    win_loss = []\n",
    "                    count = 1\n",
    "                \n",
    "          return win_loss_all\n",
    "      \n",
    "      def create_gainers_losers_df(self, win_loss_all):\n",
    "          self.df_guru = pd.DataFrame( win_loss_all, columns = ['Stock', 'Company', 'Price', 'Price_Change'])\n",
    "        \n",
    "          dateTimeObj = datetime.now()\n",
    "          self.df_guru['date_time'] = str(dateTimeObj)\n",
    "          \n",
    "          return self.df_guru\n",
    "      \n",
    "      def backup_file(self):     \n",
    "          my_file = Path(self.main)\n",
    "          if my_file.is_file():\n",
    "             df_guru_bkup = pd.read_csv(self.main)\n",
    "             df_guru_bkup.to_csv(self.backup) \n",
    "          \n",
    "        \n",
    "          return\n",
    "        \n",
    "      def initialize_file(self):\n",
    "          self.backup_file()\n",
    "          df_initialize = pd.DataFrame([['','','','','']], \\\n",
    "                          columns = ['Stock', 'Company', 'Price', 'Price_Change', 'date_time'])\n",
    "          df_initialize.to_csv(self.main)\n",
    "        \n",
    "        \n",
    "      def append_file(self):\n",
    "          self.backup_file()\n",
    "          f = open(self.main, 'a') # Open file as append mode\n",
    "          self.df_guru.to_csv(f, header = False)\n",
    "          f.close()\n",
    "        \n",
    "          return\n",
    "        \n",
    "      def print_file(self,file):\n",
    "          my_file = Path(file)\n",
    "          if my_file.is_file():\n",
    "             return print(pd.read_csv(file))\n",
    "          else:\n",
    "             print(f\"File {file} does NOT exist\")       \n",
    "\n",
    "      \n",
    "URL = 'https://www.gurufocus.com/stock-market-valuations.php'\n",
    "main = \"Losers_and_Gainers1.csv\"\n",
    "backup = \"Losers_and_Gainers1_bkup.csv\"\n",
    "guru =  Guru_Scrape(URL, main, backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guru.initialize_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G_L_array = guru.find__gainers_losers()\n",
    "print(guru.create_gainers_losers_df(G_L_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guru.print_file(backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "guru.append_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guru.print_file(main)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
